{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available and set PyTorch to use the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to predict a batch\n",
    "# def predict_batch(batch):\n",
    "#     inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#     outputs = model(**inputs)\n",
    "#     return torch.argmax(outputs.logits, dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modify the predict_batch function to move data to the GPU\n",
    "# def predict_batch(batch):\n",
    "#     inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "#     # Move tensors to the specified device\n",
    "#     inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     return torch.argmax(outputs.logits, dim=1).cpu().numpy()  # Move results back to CPU for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(batch):\n",
    "    try:\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        # Move tensors to the specified device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        return torch.argmax(outputs.logits, dim=1).cpu().numpy()  # Move results back to CPU for further processing\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        # Assign default prediction of 1 for the entire batch in case of an error\n",
    "        return [1] * len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ucberkeley_measuring_hate_speech_dataset_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hatespeech'] = data['hatespeech'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.sample(n=13500, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>text</th>\n",
       "      <th>annotator_gender</th>\n",
       "      <th>annotator_educ</th>\n",
       "      <th>annotator_income</th>\n",
       "      <th>annotator_ideology</th>\n",
       "      <th>annotator_age</th>\n",
       "      <th>annotator_trans</th>\n",
       "      <th>annotator_race</th>\n",
       "      <th>annotator_religion</th>\n",
       "      <th>annotator_sexuality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20005</td>\n",
       "      <td>692</td>\n",
       "      <td>2</td>\n",
       "      <td>careful wish always wanted feel huge cock hole...</td>\n",
       "      <td>male</td>\n",
       "      <td>college_grad_ba</td>\n",
       "      <td>50k-100k</td>\n",
       "      <td>slightly_liberal</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>nothing</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20050</td>\n",
       "      <td>8399</td>\n",
       "      <td>0</td>\n",
       "      <td>dont care threatened feel cant go throwing res...</td>\n",
       "      <td>female</td>\n",
       "      <td>college_grad_ba</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>latinx</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22882</td>\n",
       "      <td>6516</td>\n",
       "      <td>1</td>\n",
       "      <td>interracial threeway young pawg druffbandit ma...</td>\n",
       "      <td>female</td>\n",
       "      <td>some_college</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>liberal</td>\n",
       "      <td>23.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>asian</td>\n",
       "      <td>nothing</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20055</td>\n",
       "      <td>9571</td>\n",
       "      <td>0</td>\n",
       "      <td>plenty evidence woman nonwhite people disadvan...</td>\n",
       "      <td>female</td>\n",
       "      <td>college_grad_aa</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>liberal</td>\n",
       "      <td>53.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>other</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20065</td>\n",
       "      <td>1061</td>\n",
       "      <td>0</td>\n",
       "      <td>notwithstanding marriyum aurangzeb sahibas pol...</td>\n",
       "      <td>female</td>\n",
       "      <td>professional_degree</td>\n",
       "      <td>100k-200k</td>\n",
       "      <td>liberal</td>\n",
       "      <td>44.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>nothing</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>20013</td>\n",
       "      <td>4207</td>\n",
       "      <td>2</td>\n",
       "      <td>hate people woman especially look mad got dog ...</td>\n",
       "      <td>female</td>\n",
       "      <td>professional_degree</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>slightly_liberal</td>\n",
       "      <td>25.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>asian</td>\n",
       "      <td>hindu</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>38182</td>\n",
       "      <td>4124</td>\n",
       "      <td>2</td>\n",
       "      <td>haha love fag empty stare dumb willing obeying...</td>\n",
       "      <td>female</td>\n",
       "      <td>college_grad_aa</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>slightly_liberal</td>\n",
       "      <td>34.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>nothing</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>737</td>\n",
       "      <td>9885</td>\n",
       "      <td>2</td>\n",
       "      <td>shes disgusting id let suck cock</td>\n",
       "      <td>male</td>\n",
       "      <td>some_college</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>slightly_conservative</td>\n",
       "      <td>34.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>nothing</td>\n",
       "      <td>gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>46466</td>\n",
       "      <td>6117</td>\n",
       "      <td>0</td>\n",
       "      <td>he black sorry disappoint dewayne craddock</td>\n",
       "      <td>male</td>\n",
       "      <td>high_school_grad</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>slightly_liberal</td>\n",
       "      <td>31.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>20068</td>\n",
       "      <td>7717</td>\n",
       "      <td>2</td>\n",
       "      <td>trump jew true friend hope trump next u presid...</td>\n",
       "      <td>female</td>\n",
       "      <td>college_grad_ba</td>\n",
       "      <td>50k-100k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>33.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment_id  annotator_id  hatespeech  \\\n",
       "0           20005           692           2   \n",
       "1           20050          8399           0   \n",
       "2           22882          6516           1   \n",
       "3           20055          9571           0   \n",
       "4           20065          1061           0   \n",
       "...           ...           ...         ...   \n",
       "13495       20013          4207           2   \n",
       "13496       38182          4124           2   \n",
       "13497         737          9885           2   \n",
       "13498       46466          6117           0   \n",
       "13499       20068          7717           2   \n",
       "\n",
       "                                                    text annotator_gender  \\\n",
       "0      careful wish always wanted feel huge cock hole...             male   \n",
       "1      dont care threatened feel cant go throwing res...           female   \n",
       "2      interracial threeway young pawg druffbandit ma...           female   \n",
       "3      plenty evidence woman nonwhite people disadvan...           female   \n",
       "4      notwithstanding marriyum aurangzeb sahibas pol...           female   \n",
       "...                                                  ...              ...   \n",
       "13495  hate people woman especially look mad got dog ...           female   \n",
       "13496  haha love fag empty stare dumb willing obeying...           female   \n",
       "13497                   shes disgusting id let suck cock             male   \n",
       "13498         he black sorry disappoint dewayne craddock             male   \n",
       "13499  trump jew true friend hope trump next u presid...           female   \n",
       "\n",
       "            annotator_educ annotator_income     annotator_ideology  \\\n",
       "0          college_grad_ba         50k-100k       slightly_liberal   \n",
       "1          college_grad_ba          10k-50k                neutral   \n",
       "2             some_college          10k-50k                liberal   \n",
       "3          college_grad_aa          10k-50k                liberal   \n",
       "4      professional_degree        100k-200k                liberal   \n",
       "...                    ...              ...                    ...   \n",
       "13495  professional_degree          10k-50k       slightly_liberal   \n",
       "13496      college_grad_aa          10k-50k       slightly_liberal   \n",
       "13497         some_college          10k-50k  slightly_conservative   \n",
       "13498     high_school_grad          10k-50k       slightly_liberal   \n",
       "13499      college_grad_ba         50k-100k                neutral   \n",
       "\n",
       "       annotator_age annotator_trans annotator_race annotator_religion  \\\n",
       "0               30.0       cisgender          white            nothing   \n",
       "1               36.0       cisgender         latinx          christian   \n",
       "2               23.0       cisgender          asian            nothing   \n",
       "3               53.0       cisgender          white              other   \n",
       "4               44.0       cisgender          white            nothing   \n",
       "...              ...             ...            ...                ...   \n",
       "13495           25.0       cisgender          asian              hindu   \n",
       "13496           34.0       cisgender          white            nothing   \n",
       "13497           34.0       cisgender          white            nothing   \n",
       "13498           31.0       cisgender          white          christian   \n",
       "13499           33.0       cisgender          white          christian   \n",
       "\n",
       "      annotator_sexuality  \n",
       "0                straight  \n",
       "1                straight  \n",
       "2                   other  \n",
       "3                straight  \n",
       "4                straight  \n",
       "...                   ...  \n",
       "13495            straight  \n",
       "13496            straight  \n",
       "13497                 gay  \n",
       "13498            straight  \n",
       "13499            straight  \n",
       "\n",
       "[13500 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "texts = df['text'].tolist()\n",
    "labels = df['hatespeech'].tolist()\n",
    "dataset = HateSpeechDataset(texts, labels)\n",
    "\n",
    "# Split the dataset for training and validation\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b90da47f2846378ea2d21801ad6018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7475, 'learning_rate': 5e-05, 'epoch': 0.33}\n",
      "{'loss': 0.6411, 'learning_rate': 4.383781119053488e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6276, 'learning_rate': 3.767562238106976e-05, 'epoch': 0.99}\n",
      "{'loss': 0.5887, 'learning_rate': 3.151343357160463e-05, 'epoch': 1.32}\n",
      "{'loss': 0.548, 'learning_rate': 2.5351244762139513e-05, 'epoch': 1.65}\n",
      "{'loss': 0.5692, 'learning_rate': 1.918905595267439e-05, 'epoch': 1.97}\n",
      "{'loss': 0.5052, 'learning_rate': 1.3026867143209267e-05, 'epoch': 2.3}\n",
      "{'loss': 0.4593, 'learning_rate': 6.864678333744145e-06, 'epoch': 2.63}\n",
      "{'loss': 0.4675, 'learning_rate': 7.024895242790239e-07, 'epoch': 2.96}\n",
      "{'train_runtime': 646.6193, 'train_samples_per_second': 56.37, 'train_steps_per_second': 7.047, 'train_loss': 0.5708289034460259, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the fine-tuned model (for your 100000 texts)\n",
    "# Load your dataset here\n",
    "large_dataset = pd.read_csv(\"ucberkeley_measuring_hate_speech_dataset_testing.csv\")\n",
    "\n",
    "testing_dataset = large_dataset[\"text\"].tolist()\n",
    "\n",
    "# Tokenize and predict\n",
    "#predictions = model(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Predictions: [0 0 0 0 0 0 2 2 0 2 0 0 0 0 2 2 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Test prediction with a small set of texts (20 texts)\n",
    "test_texts = text_list = large_dataset['text'].head(20).tolist()\n",
    "\n",
    "test_predictions = predict_batch(test_texts)\n",
    "print(\"Test Predictions:\", test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing and resuming\n",
    "checkpoint_file = \"predictions_checkpoint.csv\"\n",
    "try:\n",
    "    # Try to load existing checkpoint\n",
    "    checkpoint_data = pd.read_csv(checkpoint_file)\n",
    "    start_index = checkpoint_data.shape[0]\n",
    "    predictions = checkpoint_data[\"predictions\"].tolist()\n",
    "except FileNotFoundError:\n",
    "    # If no checkpoint exists, start from scratch\n",
    "    start_index = 0\n",
    "    predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/124 [00:00<00:28,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during prediction: Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [46:31<00:00, 22.51s/it] \n"
     ]
    }
   ],
   "source": [
    "# Process in batches and save checkpoints\n",
    "batch_size = 1000\n",
    "for i in tqdm(range(start_index, len(testing_dataset), batch_size)):\n",
    "    batch = testing_dataset[i:i + batch_size]\n",
    "    batch_predictions = predict_batch(batch)\n",
    "    predictions.extend(batch_predictions)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    pd.DataFrame({\"predictions\": predictions}).to_csv(checkpoint_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to DataFrame\n",
    "final_predictions = pd.DataFrame({\"text\": testing_dataset, \"predictions\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes indeed sort reminds elder lady played part...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trans woman reading tweet right beautiful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question broad criticize america country flee ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time illegals go back country origin keep free...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>starter bend one pink kick as pussy get taste ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135448</th>\n",
       "      <td>breaking news sayyed abdulmalikthe saudi regim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135449</th>\n",
       "      <td>million yemeni participated mass rally square ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135450</th>\n",
       "      <td>abeshinzo realdonaldtrump shinzoabe dictator g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135451</th>\n",
       "      <td>million yemeni participated mass rally square ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135452</th>\n",
       "      <td>op really hope commit suicide one day die as c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  predictions\n",
       "0       yes indeed sort reminds elder lady played part...            0\n",
       "1               trans woman reading tweet right beautiful            0\n",
       "2       question broad criticize america country flee ...            0\n",
       "3       time illegals go back country origin keep free...            0\n",
       "4       starter bend one pink kick as pussy get taste ...            0\n",
       "...                                                   ...          ...\n",
       "135448  breaking news sayyed abdulmalikthe saudi regim...            0\n",
       "135449  million yemeni participated mass rally square ...            0\n",
       "135450  abeshinzo realdonaldtrump shinzoabe dictator g...            2\n",
       "135451  million yemeni participated mass rally square ...            0\n",
       "135452  op really hope commit suicide one day die as c...            2\n",
       "\n",
       "[135453 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the final predictions\n",
    "final_predictions.to_csv(\"bert_final_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
