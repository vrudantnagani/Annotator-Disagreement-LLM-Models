{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c3e03c-586f-4a68-9ff8-6214055a3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720b315a-59b5-49ec-9387-899a2b0867cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotator_gender</th>\n",
       "      <th>annotator_educ</th>\n",
       "      <th>annotator_income</th>\n",
       "      <th>annotator_ideology</th>\n",
       "      <th>annotator_age</th>\n",
       "      <th>annotator_trans</th>\n",
       "      <th>annotator_race</th>\n",
       "      <th>annotator_religion</th>\n",
       "      <th>annotator_sexuality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47777</td>\n",
       "      <td>10873</td>\n",
       "      <td>yes indeed sort reminds elder lady played part...</td>\n",
       "      <td>male</td>\n",
       "      <td>college_grad_ba</td>\n",
       "      <td>&lt;10k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>25.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39773</td>\n",
       "      <td>2790</td>\n",
       "      <td>trans woman reading tweet right beautiful</td>\n",
       "      <td>female</td>\n",
       "      <td>some_college</td>\n",
       "      <td>&lt;10k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47101</td>\n",
       "      <td>3379</td>\n",
       "      <td>question broad criticize america country flee ...</td>\n",
       "      <td>male</td>\n",
       "      <td>some_college</td>\n",
       "      <td>100k-200k</td>\n",
       "      <td>slightly_conservative</td>\n",
       "      <td>41.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>nothing</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43625</td>\n",
       "      <td>7365</td>\n",
       "      <td>time illegals go back country origin keep free...</td>\n",
       "      <td>male</td>\n",
       "      <td>high_school_grad</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>42.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>atheist</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12538</td>\n",
       "      <td>488</td>\n",
       "      <td>starter bend one pink kick as pussy get taste ...</td>\n",
       "      <td>female</td>\n",
       "      <td>masters</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>27.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135448</th>\n",
       "      <td>37080</td>\n",
       "      <td>8590</td>\n",
       "      <td>breaking news sayyed abdulmalikthe saudi regim...</td>\n",
       "      <td>female</td>\n",
       "      <td>college_grad_aa</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>no_opinion</td>\n",
       "      <td>56.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>latinx</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135449</th>\n",
       "      <td>22986</td>\n",
       "      <td>8303</td>\n",
       "      <td>million yemeni participated mass rally square ...</td>\n",
       "      <td>female</td>\n",
       "      <td>college_grad_ba</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>extremely_liberal</td>\n",
       "      <td>28.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>other</td>\n",
       "      <td>bisexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135450</th>\n",
       "      <td>21008</td>\n",
       "      <td>6207</td>\n",
       "      <td>abeshinzo realdonaldtrump shinzoabe dictator g...</td>\n",
       "      <td>female</td>\n",
       "      <td>some_college</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>liberal</td>\n",
       "      <td>47.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135451</th>\n",
       "      <td>22986</td>\n",
       "      <td>7886</td>\n",
       "      <td>million yemeni participated mass rally square ...</td>\n",
       "      <td>male</td>\n",
       "      <td>college_grad_aa</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>conservative</td>\n",
       "      <td>37.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>nothing</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135452</th>\n",
       "      <td>14785</td>\n",
       "      <td>6897</td>\n",
       "      <td>op really hope commit suicide one day die as c...</td>\n",
       "      <td>female</td>\n",
       "      <td>high_school_grad</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>slightly_conservative</td>\n",
       "      <td>25.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>latinx</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135453 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        comment_id  annotator_id  \\\n",
       "0            47777         10873   \n",
       "1            39773          2790   \n",
       "2            47101          3379   \n",
       "3            43625          7365   \n",
       "4            12538           488   \n",
       "...            ...           ...   \n",
       "135448       37080          8590   \n",
       "135449       22986          8303   \n",
       "135450       21008          6207   \n",
       "135451       22986          7886   \n",
       "135452       14785          6897   \n",
       "\n",
       "                                                     text annotator_gender  \\\n",
       "0       yes indeed sort reminds elder lady played part...             male   \n",
       "1               trans woman reading tweet right beautiful           female   \n",
       "2       question broad criticize america country flee ...             male   \n",
       "3       time illegals go back country origin keep free...             male   \n",
       "4       starter bend one pink kick as pussy get taste ...           female   \n",
       "...                                                   ...              ...   \n",
       "135448  breaking news sayyed abdulmalikthe saudi regim...           female   \n",
       "135449  million yemeni participated mass rally square ...           female   \n",
       "135450  abeshinzo realdonaldtrump shinzoabe dictator g...           female   \n",
       "135451  million yemeni participated mass rally square ...             male   \n",
       "135452  op really hope commit suicide one day die as c...           female   \n",
       "\n",
       "          annotator_educ annotator_income     annotator_ideology  \\\n",
       "0        college_grad_ba             <10k                neutral   \n",
       "1           some_college             <10k                neutral   \n",
       "2           some_college        100k-200k  slightly_conservative   \n",
       "3       high_school_grad          10k-50k                neutral   \n",
       "4                masters          10k-50k                neutral   \n",
       "...                  ...              ...                    ...   \n",
       "135448   college_grad_aa          10k-50k             no_opinion   \n",
       "135449   college_grad_ba          10k-50k      extremely_liberal   \n",
       "135450      some_college          10k-50k                liberal   \n",
       "135451   college_grad_aa          10k-50k           conservative   \n",
       "135452  high_school_grad          10k-50k  slightly_conservative   \n",
       "\n",
       "        annotator_age annotator_trans annotator_race annotator_religion  \\\n",
       "0                25.0       cisgender          white          christian   \n",
       "1                30.0       cisgender          white          christian   \n",
       "2                41.0       cisgender          white            nothing   \n",
       "3                42.0       cisgender          white            atheist   \n",
       "4                27.0       cisgender          white          christian   \n",
       "...               ...             ...            ...                ...   \n",
       "135448           56.0       cisgender         latinx          christian   \n",
       "135449           28.0       cisgender          white              other   \n",
       "135450           47.0       cisgender          white          christian   \n",
       "135451           37.0       cisgender          white            nothing   \n",
       "135452           25.0       cisgender         latinx          christian   \n",
       "\n",
       "       annotator_sexuality  \n",
       "0                 straight  \n",
       "1                 straight  \n",
       "2                 straight  \n",
       "3                 straight  \n",
       "4                 straight  \n",
       "...                    ...  \n",
       "135448            straight  \n",
       "135449            bisexual  \n",
       "135450            straight  \n",
       "135451            straight  \n",
       "135452            straight  \n",
       "\n",
       "[135453 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ucberkeley_measuring_hate_speech_dataset_testing.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6811b91-6277-4322-937f-a0c8fd17f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=stopwords.words('english')):\n",
    "\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in lst_stopwords]\n",
    "\n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "\n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "\n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         yes indeed sort reminds elder lady played part...\n",
       "1                 trans woman reading tweet right beautiful\n",
       "2         question broad criticize america country flee ...\n",
       "3         time illegals go back country origin keep free...\n",
       "4         starter bend one pink kick as pussy get taste ...\n",
       "                                ...                        \n",
       "135448    breaking news sayyed abdulmalikthe saudi regim...\n",
       "135449    million yemeni participated mass rally square ...\n",
       "135450    abeshinzo realdonaldtrump shinzoabe dictator g...\n",
       "135451    million yemeni participated mass rally square ...\n",
       "135452    op really hope commit suicide one day die as c...\n",
       "Name: text, Length: 135453, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a030de-5553-4eb3-930d-40d7c264db4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Vrudant/nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vrudant\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Vrudant/nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vrudant\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text, flg_stemm, flg_lemm, lst_stopwords)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flg_lemm \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     lem \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;241m.\u001b[39mwordnet\u001b[38;5;241m.\u001b[39mWordNetLemmatizer()\n\u001b[1;32m---> 21\u001b[0m     lst_text \u001b[38;5;241m=\u001b[39m [lem\u001b[38;5;241m.\u001b[39mlemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m lst_text]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m## back to string from list\u001b[39;00m\n\u001b[0;32m     24\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lst_text)\n",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flg_lemm \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     lem \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;241m.\u001b[39mwordnet\u001b[38;5;241m.\u001b[39mWordNetLemmatizer()\n\u001b[1;32m---> 21\u001b[0m     lst_text \u001b[38;5;241m=\u001b[39m [\u001b[43mlem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m lst_text]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m## back to string from list\u001b[39;00m\n\u001b[0;32m     24\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lst_text)\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\stem\\wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\corpus\\util.py:89\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# This is where the magic happens!  Transform ourselves into\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# the corpus by modifying our own __dict__ and __class__ to\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# match that of the corpus.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1176\u001b[0m, in \u001b[0;36mWordNetCorpusReader.__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe multilingual functions are not available with this Wordnet version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprovenances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43momw_prov\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;66;03m# A cache to store the wordnet data of multiple languages\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang_data \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1285\u001b[0m, in \u001b[0;36mWordNetCorpusReader.omw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m provdict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1284\u001b[0m provdict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1285\u001b[0m fileids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_omw_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileids\u001b[49m()\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fileid \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[0;32m   1287\u001b[0m     prov, langfile \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(fileid)\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Vrudant\\.conda\\envs\\tfgpu\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Vrudant/nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Vrudant\\\\.conda\\\\envs\\\\tfgpu\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vrudant\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df.text.apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bedaa2f-acbf-419a-b00e-a3eda4eefaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         yes indeed sort reminds elder lady played part...\n",
       "1                 trans woman reading tweet right beautiful\n",
       "2         question broad criticize america country flee ...\n",
       "3         time illegals go back country origin keep free...\n",
       "4         starter bend one pink kick as pussy get taste ...\n",
       "                                ...                        \n",
       "135448    breaking news sayyed abdulmalikthe saudi regim...\n",
       "135449    million yemeni participated mass rally square ...\n",
       "135450    abeshinzo realdonaldtrump shinzoabe dictator g...\n",
       "135451    million yemeni participated mass rally square ...\n",
       "135452    op really hope commit suicide one day die as c...\n",
       "Name: text, Length: 135453, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4367ed-76cd-49ad-9db6-277c57603bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotator_gender</th>\n",
       "      <th>annotator_educ</th>\n",
       "      <th>annotator_income</th>\n",
       "      <th>annotator_ideology</th>\n",
       "      <th>annotator_age</th>\n",
       "      <th>annotator_trans</th>\n",
       "      <th>annotator_race</th>\n",
       "      <th>annotator_religion</th>\n",
       "      <th>annotator_sexuality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47777</td>\n",
       "      <td>10873</td>\n",
       "      <td>yes indeed sort reminds elder lady played part...</td>\n",
       "      <td>male</td>\n",
       "      <td>college_grad_ba</td>\n",
       "      <td>&lt;10k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>25.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39773</td>\n",
       "      <td>2790</td>\n",
       "      <td>trans woman reading tweet right beautiful</td>\n",
       "      <td>female</td>\n",
       "      <td>some_college</td>\n",
       "      <td>&lt;10k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47101</td>\n",
       "      <td>3379</td>\n",
       "      <td>question broad criticize america country flee ...</td>\n",
       "      <td>male</td>\n",
       "      <td>some_college</td>\n",
       "      <td>100k-200k</td>\n",
       "      <td>slightly_conservative</td>\n",
       "      <td>41.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>nothing</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43625</td>\n",
       "      <td>7365</td>\n",
       "      <td>time illegals go back country origin keep free...</td>\n",
       "      <td>male</td>\n",
       "      <td>high_school_grad</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>42.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>atheist</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12538</td>\n",
       "      <td>488</td>\n",
       "      <td>starter bend one pink kick as pussy get taste ...</td>\n",
       "      <td>female</td>\n",
       "      <td>masters</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>neutral</td>\n",
       "      <td>27.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11001</td>\n",
       "      <td>527</td>\n",
       "      <td>sound like kinda wholsesome life id die never ...</td>\n",
       "      <td>male</td>\n",
       "      <td>high_school_grad</td>\n",
       "      <td>10k-50k</td>\n",
       "      <td>extremely_liberal</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>other</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13168</td>\n",
       "      <td>3275</td>\n",
       "      <td>fuck insignificant simple minded redneck get v...</td>\n",
       "      <td>male</td>\n",
       "      <td>high_school_grad</td>\n",
       "      <td>50k-100k</td>\n",
       "      <td>extremely_conservative</td>\n",
       "      <td>37.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>black</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17034</td>\n",
       "      <td>6801</td>\n",
       "      <td>fuck insufferable retarded faggot</td>\n",
       "      <td>male</td>\n",
       "      <td>college_grad_ba</td>\n",
       "      <td>100k-200k</td>\n",
       "      <td>extremely_liberal</td>\n",
       "      <td>47.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>atheist</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40171</td>\n",
       "      <td>10363</td>\n",
       "      <td>omg ego young young inexperienced woman displa...</td>\n",
       "      <td>female</td>\n",
       "      <td>college_grad_aa</td>\n",
       "      <td>50k-100k</td>\n",
       "      <td>slightly_conservative</td>\n",
       "      <td>35.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>christian</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1006</td>\n",
       "      <td>10615</td>\n",
       "      <td>worthless whore tit look nice bite mark cum</td>\n",
       "      <td>female</td>\n",
       "      <td>masters</td>\n",
       "      <td>50k-100k</td>\n",
       "      <td>extremely_liberal</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cisgender</td>\n",
       "      <td>white</td>\n",
       "      <td>atheist</td>\n",
       "      <td>straight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id  annotator_id  \\\n",
       "0       47777         10873   \n",
       "1       39773          2790   \n",
       "2       47101          3379   \n",
       "3       43625          7365   \n",
       "4       12538           488   \n",
       "5       11001           527   \n",
       "6       13168          3275   \n",
       "7       17034          6801   \n",
       "8       40171         10363   \n",
       "9        1006         10615   \n",
       "\n",
       "                                                text annotator_gender  \\\n",
       "0  yes indeed sort reminds elder lady played part...             male   \n",
       "1          trans woman reading tweet right beautiful           female   \n",
       "2  question broad criticize america country flee ...             male   \n",
       "3  time illegals go back country origin keep free...             male   \n",
       "4  starter bend one pink kick as pussy get taste ...           female   \n",
       "5  sound like kinda wholsesome life id die never ...             male   \n",
       "6  fuck insignificant simple minded redneck get v...             male   \n",
       "7                  fuck insufferable retarded faggot             male   \n",
       "8  omg ego young young inexperienced woman displa...           female   \n",
       "9        worthless whore tit look nice bite mark cum           female   \n",
       "\n",
       "     annotator_educ annotator_income      annotator_ideology  annotator_age  \\\n",
       "0   college_grad_ba             <10k                 neutral           25.0   \n",
       "1      some_college             <10k                 neutral           30.0   \n",
       "2      some_college        100k-200k   slightly_conservative           41.0   \n",
       "3  high_school_grad          10k-50k                 neutral           42.0   \n",
       "4           masters          10k-50k                 neutral           27.0   \n",
       "5  high_school_grad          10k-50k       extremely_liberal           30.0   \n",
       "6  high_school_grad         50k-100k  extremely_conservative           37.0   \n",
       "7   college_grad_ba        100k-200k       extremely_liberal           47.0   \n",
       "8   college_grad_aa         50k-100k   slightly_conservative           35.0   \n",
       "9           masters         50k-100k       extremely_liberal           30.0   \n",
       "\n",
       "  annotator_trans annotator_race annotator_religion annotator_sexuality  \n",
       "0       cisgender          white          christian            straight  \n",
       "1       cisgender          white          christian            straight  \n",
       "2       cisgender          white            nothing            straight  \n",
       "3       cisgender          white            atheist            straight  \n",
       "4       cisgender          white          christian            straight  \n",
       "5       cisgender          white              other            straight  \n",
       "6       cisgender          black          christian            straight  \n",
       "7       cisgender          white            atheist            straight  \n",
       "8       cisgender          white          christian            straight  \n",
       "9       cisgender          white            atheist            straight  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d8a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'text' column: 1\n"
     ]
    }
   ],
   "source": [
    "null_count = df['text'].isnull().sum()\n",
    "print(f\"Number of null values in 'text' column: {null_count}\")\n",
    "\n",
    "# Fill null values with 'test'\n",
    "if null_count > 0:\n",
    "    df['text'] = df['text'].fillna('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ucberkeley_measuring_hate_speech_dataset_testing.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
